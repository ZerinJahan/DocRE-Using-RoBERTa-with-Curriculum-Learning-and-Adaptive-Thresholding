# Document-Level Relation Extraction (DocRE) Using RoBERTa with Curriculum Learning and Adaptive Thresholding
The project titled "Document-Level Relation Extraction (DocRE) Using RoBERTa with Curriculum Learning and Adaptive Thresholding" focuses on building a lightweight, high-recall system for extracting semantic relationships between entities across full documents. Using the improved Re-DocRED dataset, it employs a RoBERTa-based model with advanced preprocessing, Curriculum Learning to stabilise training, and Adaptive Thresholding to optimise predictions for imbalanced data. Achieving 96.51% recall on minority class relations, 93.11% weighted F1-score, and 88.17% overall accuracy in just 8.47 minutes of training, the system is implemented in Python using PyTorch, Hugging Face Transformers, NumPy, Pandas, and Scikit-learn, providing a scalable, memory-efficient solution for real-world document-level relation extraction.
